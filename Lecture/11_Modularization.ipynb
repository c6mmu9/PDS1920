{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "rise": {
      "enable_chalkboard": false,
      "overlay": "<div class='background'></div><div class='header'>WS 19/20</br>PDS</div><div class='logo'><img src='images/unilogo.png'></div><div class='bar'></div>",
      "scroll": true,
      "slideNumber": "h.v"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "11_Modularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wi3jmu/PDS1920/blob/master/Lecture/11_Modularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSJ9sDsgWkKq",
        "colab_type": "text"
      },
      "source": [
        "<div class='bar_title'></div>\n",
        "\n",
        "*Practical Data Science*\n",
        "\n",
        "# Modularization and Code Outsourcing\n",
        "\n",
        "Matthias Griebel<br>\n",
        "Chair of Information Systems and Management\n",
        "\n",
        "Winter Semester 19/20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMk8eum8WkK0",
        "colab_type": "text"
      },
      "source": [
        "__Credits__\n",
        "\n",
        "- https://realpython.com/python-modules-packages/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI9SAWcHWkKx",
        "colab_type": "text"
      },
      "source": [
        "## Modular programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV18aLG3WkK3",
        "colab_type": "text"
      },
      "source": [
        "___Definition___\n",
        "\n",
        "Modular programming refers to the process of breaking a large, unwieldy programming task into separate, smaller, more manageable subtasks or modules. Individual modules can then be cobbled together like building blocks to create a larger application.\n",
        "\n",
        "___Advantages___\n",
        "\n",
        "There are several advantages to modularizing code in a large application:\n",
        "\n",
        "- **Simplicity**: Rather than focusing on the entire problem at hand, a module typically focuses on one relatively small portion of the problem. If you’re working on a single module, you’ll have a smaller problem domain to wrap your head around. This makes development easier and less error-prone.\n",
        "\n",
        "- **Maintainability**: Modules are typically designed so that they enforce logical boundaries between different problem domains. If modules are written in a way that minimizes interdependency, there is decreased likelihood that modifications to a single module will have an impact on other parts of the program. (You may even be able to make changes to a module without having any knowledge of the application outside that module.) This makes it more viable for a team of many programmers to work collaboratively on a large application.\n",
        "\n",
        "- **Reusability**: Functionality defined in a single module can be easily reused (through an appropriately defined interface) by other parts of the application. This eliminates the need to recreate duplicate code.\n",
        "\n",
        "- **Scoping**: Modules typically define a separate namespace, which helps avoid collisions between identifiers in different areas of a program. (One of the tenets in the [Zen of Python](https://www.python.org/dev/peps/pep-0020/) is \"Namespaces are one honking great idea—let’s do more of those!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ln9QzJcbXBg",
        "colab_type": "text"
      },
      "source": [
        "#### Python Modules: Overview\n",
        "\n",
        "There are actually three different ways to define a module in Python:\n",
        "\n",
        "1. A module can be written in Python itself.\n",
        "2. A module can be written in C and loaded dynamically at run-time, like the re (regular expression) module.\n",
        "3. A built-in module is intrinsically contained in the interpreter, like the itertools module.\n",
        "\n",
        "A module’s contents are accessed the same way in all three cases: with the `import` statement.\n",
        "\n",
        "Here, the focus will mostly be on modules that are written in Python. The cool thing about modules written in Python is that they are exceedingly straightforward to build. All you need to do is create a file that contains legitimate Python code and then give the file a name with a .py extension. That’s it! No special syntax or voodoo is necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q7AaaK8X3VQ",
        "colab_type": "text"
      },
      "source": [
        "#### Further Reading\n",
        "\n",
        "- [Python Docs](https://docs.python.org/3/tutorial/modules.html)\n",
        "- Tuorials: \n",
        "  - https://www.learnpython.org/en/Modules_and_Packages\n",
        "  - https://realpython.com/python-modules-packages/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plIxhkayWkK4",
        "colab_type": "text"
      },
      "source": [
        "## Outsourcing code into modules\n",
        "\n",
        "Connect to Google Drive and update github repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCdq_VePcB6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bd624462-6ffa-4708-8dec-8ec8683fa891"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/PDS1920\n",
        "# !git clone https://github.com/wi3jmu/PDS1920.git\n",
        "!git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/PDS1920\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW9UtQO8eLQy",
        "colab_type": "text"
      },
      "source": [
        "__Autoreload__\n",
        "\n",
        "``autoreload`` is an IPython extension that reloads modules\n",
        "automatically before executing the line of code typed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os8BaFHmeLb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obSaxR14dsXr",
        "colab_type": "text"
      },
      "source": [
        "### Export to .py files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDDjYye0hyIL",
        "colab_type": "text"
      },
      "source": [
        "Write file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4-A31DcCI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7126af11-4a0d-43f2-c3d0-a4fde4c9fdbc"
      },
      "source": [
        "%%writefile example.py\n",
        "# Fibonacci numbers module\n",
        "\n",
        "def fib(n):\n",
        "    '''Write Fibonacci series up to n'''\n",
        "    a, b = 0, 1\n",
        "    while a < n:\n",
        "        print(a, end=' ')\n",
        "        a, b = b, a+b\n",
        "    print()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting example.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYvFXzAjh4WU",
        "colab_type": "text"
      },
      "source": [
        "Append to file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYBlcXGyh96C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7569f72d-4e31-42c1-fd33-8cc5504c5cd9"
      },
      "source": [
        "%%writefile -a example.py\n",
        "\n",
        "# Empty line at beginning\n",
        "def fib2(n):   \n",
        "  '''Return Fibonacci series up to n'''\n",
        "  result = []\n",
        "  a, b = 0, 1\n",
        "  while a < n:\n",
        "    result.append(a)\n",
        "    a, b = b, a+b\n",
        "  return result"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Appending to example.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbY202-fiN6E",
        "colab_type": "text"
      },
      "source": [
        "Import and use function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxEQwWnjd-Oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3d87ac9-0d08-4d67-e0ca-ab9744cbbebf"
      },
      "source": [
        "import example\n",
        "example.fib(100)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 1 2 3 5 8 13 21 34 55 89 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5xBgCCiUkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8505cb78-0212-4d28-d76b-c947b0793af2"
      },
      "source": [
        "x = example.fib2(1000)\n",
        "x"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSGXJG68cCCe",
        "colab_type": "text"
      },
      "source": [
        "### Structuring using subfolders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DmpnXGocCP-",
        "colab_type": "text"
      },
      "source": [
        "Create folder for module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giuCUHhAcCV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5fc8922-b462-48f8-fa8a-a4e8bff37c27"
      },
      "source": [
        "!mkdir mymodule"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘mymodule’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPFWeR0icCco",
        "colab_type": "text"
      },
      "source": [
        "Create .py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_C3FfEQcCin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4a0552f2-bd80-4bf9-c8d3-9cfebd66d562"
      },
      "source": [
        "%%writefile example.py\n",
        "# Fibonacci numbers module\n",
        "\n",
        "def fib(n):\n",
        "    '''Write Fibonacci series up to n'''\n",
        "    a, b = 0, 1\n",
        "    while a < n:\n",
        "        print(a, end=' ')\n",
        "        a, b = b, a+b\n",
        "    print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting example.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuxCI_dHcCpe",
        "colab_type": "text"
      },
      "source": [
        "Import and use module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWBL7QeRcCwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f947dea4-183b-4730-b7f1-e00114df3aff"
      },
      "source": [
        "import example\n",
        "example.fib(100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 1 2 3 5 8 13 21 34 55 89 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ZhCQ5gjBA2",
        "colab_type": "text"
      },
      "source": [
        "### Exporting to Github\n",
        "\n",
        "__Option 1__\n",
        "\n",
        "Download .py file and upload file to project via the github web interface.\n",
        "\n",
        "__Option 2__\n",
        "\n",
        "Commit and push in Colab\n",
        "  - For private repositories see [here](https://stackoverflow.com/questions/48350226/methods-for-using-git-with-google-colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxDr7t9OkueH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "35048246-6a52-4222-e589-2c3b93652267"
      },
      "source": [
        "!git config --global user.email \"you@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "!git add example.py\n",
        "!git commit -m \"Example Commit\"\n",
        "!git push"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master e89db20] Example Commit\n",
            " 1 file changed, 9 insertions(+), 7 deletions(-)\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XcAj0qCcC3b",
        "colab_type": "text"
      },
      "source": [
        "## Example: RetinaNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lebv31KmlCDQ",
        "colab_type": "text"
      },
      "source": [
        "from Lecture 10:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHlClATcC_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "46e176c2-1db4-440d-e268-07231660191e"
      },
      "source": [
        "%%writefile mymodule/retinanet.py\n",
        "from fastai.vision import *\n",
        "#Grab the convenience functions that helps us buil the Unet\n",
        "from fastai.vision.models.unet import _get_sfs_idxs, model_sizes, hook_outputs\n",
        "\n",
        "class LateralUpsampleMerge(nn.Module):\n",
        "    \"Merge the features coming from the downsample path (in `hook`) with the upsample path.\"\n",
        "    def __init__(self, ch, ch_lat, hook):\n",
        "        super().__init__()\n",
        "        self.hook = hook\n",
        "        self.conv_lat = conv2d(ch_lat, ch, ks=1, bias=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv_lat(self.hook.stored) + F.interpolate(x, self.hook.stored.shape[-2:], mode='nearest')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mymodule/retinanet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R80hs-WEfNJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d25e093c-c0a0-4dda-f8fd-835d2a96c06d"
      },
      "source": [
        "%%writefile -a mymodule/retinanet.py\n",
        "\n",
        "# Empty line at beginning\n",
        "class RetinaNet(nn.Module):\n",
        "    \"Implements RetinaNet from https://arxiv.org/abs/1708.02002\"\n",
        "    def __init__(self, encoder:nn.Module, n_classes, final_bias=0., chs=256, n_anchors=9, flatten=True):\n",
        "        super().__init__()\n",
        "        self.n_classes,self.flatten = n_classes,flatten\n",
        "        imsize = (256,256)\n",
        "        sfs_szs = model_sizes(encoder, size=imsize)\n",
        "        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n",
        "        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n",
        "        self.encoder = encoder\n",
        "        self.c5top5 = conv2d(sfs_szs[-1][1], chs, ks=1, bias=True)\n",
        "        self.c5top6 = conv2d(sfs_szs[-1][1], chs, stride=2, bias=True)\n",
        "        self.p6top7 = nn.Sequential(nn.ReLU(), conv2d(chs, chs, stride=2, bias=True))\n",
        "        self.merges = nn.ModuleList([LateralUpsampleMerge(chs, sfs_szs[idx][1], hook) \n",
        "                                     for idx,hook in zip(sfs_idxs[0:2], self.sfs[0:2])])\n",
        "        self.smoothers = nn.ModuleList([conv2d(chs, chs, 3, bias=True) for _ in range(3)])\n",
        "        self.classifier = self._head_subnet(n_classes, n_anchors, final_bias, chs=chs)\n",
        "        self.box_regressor = self._head_subnet(4, n_anchors, 0., chs=chs)\n",
        "        \n",
        "    def _head_subnet(self, n_classes, n_anchors, final_bias=0., n_conv=4, chs=256):\n",
        "        \"Helper function to create one of the subnet for regression/classification.\"\n",
        "        layers = [conv_layer(chs, chs, bias=True, norm_type=None) for _ in range(n_conv)]\n",
        "        layers += [conv2d(chs, n_classes * n_anchors, bias=True)]\n",
        "        layers[-1].bias.data.zero_().add_(final_bias)\n",
        "        layers[-1].weight.data.fill_(0)\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def _apply_transpose(self, func, p_states, n_classes):\n",
        "        #Final result of the classifier/regressor is bs * (k * n_anchors) * h * w\n",
        "        #We make it bs * h * w * n_anchors * k then flatten in bs * -1 * k so we can contenate\n",
        "        #all the results in bs * anchors * k (the non flatten version is there for debugging only)\n",
        "        if not self.flatten: \n",
        "            sizes = [[p.size(0), p.size(2), p.size(3)] for p in p_states]\n",
        "            return [func(p).permute(0,2,3,1).view(*sz,-1,n_classes) for p,sz in zip(p_states,sizes)]\n",
        "        else:\n",
        "            return torch.cat([func(p).permute(0,2,3,1).contiguous().view(p.size(0),-1,n_classes) for p in p_states],1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        c5 = self.encoder(x)\n",
        "        p_states = [self.c5top5(c5.clone()), self.c5top6(c5)]\n",
        "        p_states.append(self.p6top7(p_states[-1]))\n",
        "        for merge in self.merges: p_states = [merge(p_states[0])] + p_states\n",
        "        for i, smooth in enumerate(self.smoothers[:3]):\n",
        "            p_states[i] = smooth(p_states[i])\n",
        "        return [self._apply_transpose(self.classifier, p_states, self.n_classes), \n",
        "                self._apply_transpose(self.box_regressor, p_states, 4),\n",
        "                [[p.size(2), p.size(3)] for p in p_states]]\n",
        "    \n",
        "    def __del__(self):\n",
        "        if hasattr(self, \"sfs\"): self.sfs.remove()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Appending to mymodule/retinanet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDAdvXNnnxRJ",
        "colab_type": "text"
      },
      "source": [
        "Now, we can conveniently load RetinaNet from the module "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCginM9Ff1M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *\n",
        "from mymodule import retinanet\n",
        "\n",
        "encoder = create_body(models.resnet50, cut=-2)\n",
        "model = retinanet.RetinaNet(encoder, 2, final_bias=-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRDF_jkigHg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2801162d-dde7-4041-eb97-53992ef469be"
      },
      "source": [
        "model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RetinaNet(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (c5top5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (c5top6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (p6top7): Sequential(\n",
              "    (0): ReLU()\n",
              "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  )\n",
              "  (merges): ModuleList(\n",
              "    (0): LateralUpsampleMerge(\n",
              "      (conv_lat): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (1): LateralUpsampleMerge(\n",
              "      (conv_lat): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (smoothers): ModuleList(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (box_regressor): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}